{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ATMS597_Project5_Arka.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ceumy0nXkm_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set your directory path\n",
        "YOUR_DIRECTORY = '/content/drive/My Drive/Colab Notebooks/Project_5/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPnkLMuxV7tw",
        "colab_type": "code",
        "outputId": "f553e7a9-d126-4b05-f43a-43a3618ba8c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#!mkdir YOUR_DIRECTORY + 'project5_data/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E_0_y5o_-w_c",
        "colab": {}
      },
      "source": [
        "# Pulling KSTC Observations from NCDC for 2000-2020\n",
        "years = np.arange(2000, 2021)\n",
        "months = np.arange(1, 13)\n",
        "for y in years:\n",
        "    print(y)\n",
        "    for m in months:\n",
        "        try:\n",
        "            wget.download('ftp://ftp.ncdc.noaa.gov/pub/data/asos-fivemin/6401-' + str(y) + '/64010KSTC' + str(y) + str(m).zfill(2) + '.dat', out = YOUR_DIRECTORY + 'project5_data/')\n",
        "        except:\n",
        "            print(\"All current files grabbed\")\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDBIrpvR9sY0",
        "colab_type": "code",
        "outputId": "93c7793d-2e86-4628-ebc7-b2513b4dec0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "\n",
        "# Processing KSTC Observational data from 2000-2020\n",
        "for yr in range(2000, 2020):\n",
        "  print('Year = ', yr)\n",
        "  files = sorted(glob.glob(YOUR_DIRECTORY + 'project5_data/64010KSTC' + str(yr) + '*.dat'))\n",
        "\n",
        "  for ifile in range(0, len(files)):\n",
        "      print(ifile)\n",
        "      f = open(files[ifile], 'rb')\n",
        "      df = pd.DataFrame([str(f.readline()).replace('\\\\n\\'', '').replace('b\\'', '').strip().split(' ')])\n",
        "      for line in f:\n",
        "          data = pd.DataFrame([str(f.readline()).replace('\\\\n\\'', '').replace('b\\'', '').strip().split(' ')])\n",
        "          df = pd.concat([df, data], ignore_index = True)  \n",
        "      # df = pd.DataFrame([line.strip().split(' ') for line in open(files[ifile], 'r')])\n",
        "      del df[3]\n",
        "      n_cols = len(df.columns)\n",
        "\n",
        "      ## Setting initial set of column names, and then writing them to an output file, with remaining number of columns set to X\n",
        "      columns = ['StnNo', 'ContainsDate', 'Time', \"Interval\", 'Sttn', 'UTC', 'Type', 'Wind', \"Weath/Obstr\", 'SkyCond', 'Temp',\n",
        "                    'n_days', 'MSLP', 'RelHum', ' ', 'WndDir/Spd', 'WindMagnetic', 'RMK', 'AO2']\n",
        "      out_name = files[ifile].replace(YOUR_DIRECTORY + 'project5_data/', YOUR_DIRECTORY + 'project5_data/reviewed')\n",
        "      out = open(out_name, 'w')\n",
        "      out.write('date'+','+'timeofday'+','+'Wind'+','+'Wind_Direction'+','+'Wind_Speed'+','+'Gusts'+','+'Variable_Winds'+','+'Temperature'+','+ \n",
        "                        'Dewpoint'+','+'rhum'+','+'hourly'+','+'sixhourly'+','+'dayprecip'+','+'solid'+','+'liquid'+'\\n')\n",
        "      # new_df = pd.DataFrame(columns=new_df_columns)\n",
        "      cols_already = len(columns)\n",
        "      cols_new = []\n",
        "      cols_new = [np.append(cols_new, 'X') for i in range(n_cols-cols_already)]\n",
        "      columns = np.append(columns, cols_new)\n",
        "      df.columns = columns\n",
        "\n",
        "      for i in range(0, np.shape(df)[0]): #np.shape(df)[0]\n",
        "          try:\n",
        "            ## Processing datetime code\n",
        "            day = df['ContainsDate'][i][-8:] \n",
        "            time = df['Time'][i]\n",
        "            date = datetime.datetime.strptime(day + ' ' + time, '%m/%d/%y %H:%M:%S')\n",
        "            (h, m, s) = time.split(':')\n",
        "            timeofday = float(int(h) * 3600 + int(m) * 60 + int(s)) / (3600*24)\n",
        "            # print(date)\n",
        "            # print(timeofday)\n",
        "\n",
        "            ## Processing wind speed and direction METAR code\n",
        "            Gusts = 0\n",
        "            Wind = 0\n",
        "            Variable_Winds = 0\n",
        "            try:\n",
        "              if \"KT\" in df['Wind'][i]:\n",
        "                  Wind = 1\n",
        "                  if df['Wind'][i][0:3] == 'VRB':\n",
        "                      Variable_Winds = 1\n",
        "                  else:\n",
        "                      Variable_Winds = 0\n",
        "                      Wind_Direction = int(df['Wind'][i][0:3]) # in tens of degrees from true north\n",
        "                  Wind_Speed = int(df['Wind'][i][3:5]) # in whole knots (two digits)\n",
        "                  if df['Wind'][i][5] == 'G':\n",
        "                      Gusts = 1\n",
        "                      Gust_Speed = int(df['Wind'][i][6:8]) # speed in whole knots (two digits)\n",
        "              else:\n",
        "                  Wind = 0\n",
        "            except:\n",
        "              Wind = 0\n",
        "              Variable_Winds = 0\n",
        "              Wind_Direction = np.nan\n",
        "              Gusts=0\n",
        "              Gust_Speed=0\n",
        "\n",
        "            ## Processing temperature, relative humidity, and precipitation METAR code\n",
        "            Temp = 0\n",
        "            try:\n",
        "              if \"/\" in df['Temp'][i]:\n",
        "                  Temp = 1\n",
        "                  Temperature = df['Temp'][i].split('/')[0]\n",
        "                  if 'M' in Temperature:\n",
        "                    Temperature = int(Temperature[1:3])\n",
        "                  else:\n",
        "                    Temperature = int(Temperature)\n",
        "                  Dewpoint = df['Temp'][i].split('/')[1]\n",
        "                  if 'M' in Dewpoint:\n",
        "                    Dewpoint = int(Dewpoint[1:3])\n",
        "                  else:\n",
        "                    Dewpoint = int(Dewpoint) \n",
        "              else:\n",
        "                  Temp = 0  \n",
        "              try:\n",
        "                rhum = int(df['RelHum'][i])\n",
        "              except:\n",
        "                rhum = np.nan\n",
        "              if (rhum > 100):\n",
        "                rhum = np.nan\n",
        "            except:\n",
        "              Temp = 0\n",
        "              Temperature = np.nan\n",
        "              Dewpoint = np.nan\n",
        "              rhum = np.nan\n",
        "\n",
        "            ## Processing precipitation METAR code\n",
        "            for n in range(cols_already, n_cols): #n_cols\n",
        "              # for j in range(len(df.iloc[:,n])):\n",
        "                element = df.iloc[i,n]\n",
        "                try:\n",
        "                  if element[0] == 'P' or element[0] == '6' or element[0] == '7':\n",
        "                    if element[1] == '0':\n",
        "                      if element[0] == 'P':\n",
        "                        hourly = float(element[1:]) / 100.\n",
        "                      elif element[0]=='6':\n",
        "                        sixhourly = float(element[1:]) / 100.\n",
        "                      elif element[0] == '7':\n",
        "                        dayprecip = float(element[1:]) / 100.\n",
        "                  else:\n",
        "                    hourly = np.nan\n",
        "                    sixhourly = np.nan\n",
        "                    dayprecip = np.nan\n",
        "                except:\n",
        "                    hourly = np.nan\n",
        "                    sixhourly = np.nan\n",
        "                    dayprecip = np.nan\n",
        "\n",
        "            ## Setting liquid and frozen precipitation flags\n",
        "            frozen_flags = ['SN', 'SG', 'IC', 'PL', 'GR', 'GS']\n",
        "            liquid_flags = ['FZ', 'RA']\n",
        "            try:\n",
        "                if np.logical_or(any(flags in df['Weath/Obstr'][i] for flags in frozen_flags), any(flags in df['Temp'][i] for flags in frozen_flags)):\n",
        "                  solid = 1\n",
        "                elif np.logical_or(any(flags in df['Weath/Obstr'][i] for flags in liquid_flags), any(flags in df['Temp'][i] for flags in liquid_flags)):\n",
        "                  liquid = 1\n",
        "                else:\n",
        "                  solid = 0\n",
        "                  liquid = 0\n",
        "            except:\n",
        "                  solid = np.nan\n",
        "                  liquid = np.nan\n",
        "\n",
        "            ## Writing processed data to output file\n",
        "            # print('Wind, Wind_Direction, Wind_Speed, Gusts, Variable_Winds, Temp, Temperature, Dewpoint, rhum, hourly, sixhourly, daily:') \n",
        "            # print(str(date)+','+str(timeofday)+','+str(Wind)+','+str(Wind_Direction)+','+str(Wind_Speed)+','+str(Gusts)+','+str(Variable_Winds)\n",
        "            # +','+str(Temperature)+','+str(Dewpoint)+','+str(rhum)+','+str(hourly)+','+str(sixhourly)+','+str(dayprecip)+','+str(solid)+','+str(liquid)+'\\n')\n",
        "            out.write(str(date) + ',' + str(timeofday) + ',' + str(Wind) + ',' + str(Wind_Direction) + ',' + str(Wind_Speed) + ',' + str(Gusts) + ',' + str(Variable_Winds) + \n",
        "            ',' + str(Temperature) + ',' + str(Dewpoint) + ',' + str(rhum) + ',' + str(hourly) + ',' + str(sixhourly) + ',' + str(dayprecip) + ',' + str(solid) + \n",
        "            ',' + str(liquid) + '\\n')\n",
        "            \n",
        "          except:\n",
        "            continue\n",
        "      out.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Year =  2000\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a2ee77ff122b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\\\n\\''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b\\''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m           \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\\\n\\''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b\\''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m           \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;31m# df = pd.DataFrame([line.strip().split(' ') for line in open(files[ifile], 'r')])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    484\u001b[0m                             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                     \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                     \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# from BlockManager perspective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/generic.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_typ\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__instancecheck__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89X_P9wn4fUo",
        "colab_type": "text"
      },
      "source": [
        "<<-----Placeholder stuff below. Actual code above --------------------->>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdcp0ZSU_6Vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "infile = pd.read_csv(out_name, header=0)\n",
        "infile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2r6N3AbkitJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(files[ifile], 'rb')\n",
        "df = pd.DataFrame([str(f.readline()).replace('\\\\n\\'', '').replace('b\\'', '').strip().split(' ')])\n",
        "for line in f:\n",
        "        # print(line.decode(errors = 'ignore'))\n",
        "        data = pd.DataFrame([str(f.readline()).replace('\\\\n\\'', '').replace('b\\'', '').strip().split(' ')])\n",
        "        df = pd.concat([df, data])\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djmRcIkuSiHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(files[ifile], 'rb')\n",
        "ph = str(f.readline()).replace('\\\\n\\'', '').replace('b\\'', '').strip().split(' ')\n",
        "# ph[len(ph)-1].replace('\\\\n', '')\n",
        "ph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVeNYDQpk_pF",
        "colab_type": "text"
      },
      "source": [
        "#**Logistic Regression Model**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piWjZogilQOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_6plcY7lvf-",
        "colab_type": "text"
      },
      "source": [
        "#**Ensemble Random Forest Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLeo1BS1l065",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import brier_score_loss\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwT_XXGwmIxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in datafiles\n",
        "\n",
        "KSTC_Obs = pd.read_csv(YOUR_DIRECTORY + 'project5_data/****.csv', index_col = 'Date', parse_dates = True)\n",
        "\n",
        "print(KSTC_Obs.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug_PkrCLmpW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop all days with missing values\n",
        "features = KSTC_Obs.reset_index().dropna()\n",
        "features.dropna(inplace = True)  # There are some NaNs in the observations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE4qvErjniNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc5LW08onkg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add year, month, day as integers for use as additional features\n",
        "features['year'] = features['Date'].dt.year\n",
        "features['month'] = features['Date'].dt.month\n",
        "features['day'] = features['Date'].dt.day"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a3FoWT2npWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}